{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handline misssing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove NAN (it will remove the overall row)\n",
    "   Mostly  use when the missing data ia less than 5%\n",
    "- Impute Data (Fill rows with data, Mean etc)   \n",
    "  1) univariate\n",
    "     1) Categorical\n",
    "         - Most frequent value\n",
    "         - Missing\n",
    "     2) Numerical\n",
    "         - Filling data with mean, random value, end of distribution\n",
    "  2) Multivariate\n",
    "    - Knn imputer\n",
    "    - iterative imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Complete Case Analysis (CCA), also known as listwise deletion or case deletion, is a simple method for handling missing data in statistical analysis. In CCA, any observation (or case) with missing values in any variable is entirely excluded from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Advantages of Complete Case Analysis:\n",
    "\n",
    "    - Simple to implement and understand.\n",
    "    - Preserves the sample size of the original dataset for analysis.\n",
    "\n",
    "- Disadvantages of Complete Case Analysis:\n",
    "\n",
    "    - Can lead to biased results if missing data are not missing completely at random (MCAR).\n",
    "    - May result in loss of information, especially if missingness is related to the outcome or other variables of interest.\n",
    "    - Reduces statistical power, especially if the proportion of missing data is large.\n",
    "    - Complete Case Analysis is suitable when the missing data are missing completely at random (MCAR) and the proportion of missing data   is small. However, it may not be appropriate for datasets with non-random missingness or when missing values are informative.\n",
    "\n",
    "    - It's essential to assess the nature and patterns of missing data before deciding on the appropriate method for handling missing data. In some cases, more sophisticated techniques such as multiple imputation or maximum likelihood estimation may be more appropriate for addressing missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Numerical missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Univariate\n",
    "\"Univariate\" refers to a statistical analysis that involves only one variable. In other words, it focuses on examining the distribution, central tendency, and variability of a single variable at a time. Univariate analysis is often the first step in exploring a dataset and is useful for understanding the characteristics of individual variables before conducting more complex analyses.\n",
    "In simple words when we want fill data for 1 variable only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multivariate\n",
    "\"Multivariate\" refers to a statistical analysis that involves more than one variable. In other words, it focuses on examining the relationships between two or more variables simultaneously. Multivariate analysis allows researchers to explore complex relationships and patterns in data that cannot be captured by univariate analysis alone. \n",
    "In simple words when we want fill data for 1 variable only using other the same rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean/ Median Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Imputation:\n",
    "* In mean imputation, missing values in a dataset are replaced with the mean (average) value of the available data for that variable.\n",
    "* To impute missing values using the mean:\n",
    "   - Calculate the mean of the available data for the variable.\n",
    "   - Replace missing values with the calculated mean.\n",
    "* When to use mean imputation:\n",
    "   - Data Distribution is Approximately Symmetric: \n",
    "   - No Extreme Outliers:\n",
    "   - Continuous Numerical Variables:\n",
    "   - Missing Data is Missing Completely at Random (MCAR):    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median Imputation:\n",
    " \n",
    " * In median imputation, missing values in a dataset are replaced with the median value of the available data for that variable.\n",
    " * To impute missing values using the median:\n",
    "    - Calculate the median of the available data for the variable.\n",
    "    - Replace missing values with the calculated median.\n",
    "* When to use Median imputation:\n",
    "   - Skewed Distribution: \n",
    "   - Ordinal Variables::\n",
    "   - Categorical or Ordinal Data:\n",
    "   - Presence of Outliers:     \n",
    "   - Missing Data is Not MCAR   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbitrary Value imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Arbitrary value imputation is a method used to handle missing data by replacing the missing values with a predetermined arbitrary value. Unlike other imputation methods that use statistical measures such as the mean, median, or mode of the available data, arbitrary value imputation involves selecting a specific value to replace missing values regardless of the distribution or characteristics of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of distribution imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When data it normally distributed then it is recommend to use \n",
    "(mean + 3sigma) or(mean - 3sigma) \n",
    "\n",
    "* Mean plus three times the standard deviation (Œº + 3œÉ) is a statistical calculation used to define an upper threshold or cutoff point in a normal distribution. It represents the value that is three standard deviations above the mean of the distribution. This calculation is based on the empirical rule, also known as the 68-95-99.7 rule, which states that for a normal distribution:\n",
    "\n",
    "Approximately 68% of the data falls within one standard deviation of the mean.\n",
    "Approximately 95% of the data falls within two standard deviations of the mean.\n",
    "Approximately 99.7% of the data falls within three standard deviations of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When data is skewd then it is recommend to use \n",
    "IQR proximity.\n",
    "\n",
    "IQR proximity imputation is a method used to handle missing data by replacing missing values with values that are proximate to the quartiles of the dataset. It is based on the interquartile range (IQR), which is a measure of statistical dispersion that describes the range of the middle 50% of the data.\n",
    "\n",
    "* Calculate Interquartile Range (IQR):\n",
    "ùêº\n",
    "ùëÑ\n",
    "ùëÖ\n",
    "=\n",
    "ùëÑ\n",
    "3\n",
    "‚àí\n",
    "ùëÑ\n",
    "1\n",
    "IQR=Q3‚àíQ1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
